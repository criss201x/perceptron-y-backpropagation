import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter


rng = np.random.default_rng(0)


def augment_bias(X):
    return np.hstack([np.ones((X.shape[0], 1)), X])

def to_pm1(col):
    if col.dtype == object:
        m = {"+1": 1.0, "-1": -1.0, "1": 1.0, "-1.0": -1.0, "1.0": 1.0}
        y = col.map(m).astype(float).to_numpy()
    else:
        y = col.astype(float).to_numpy()
    # Validación
    vals = set(np.unique(y))
    assert vals.issubset({-1.0, 1.0}), f"etiquetas inválidas: {vals}"
    return y

#define el vector de pesos w
def hebb_train(X, y, eta=0.01, shuffle=False, rng=np.random.default_rng(0)):
    Xb = augment_bias(X)
    w = np.zeros(Xb.shape[1])# recomendado 
    w = rng.random(Xb.shape[1])# punto 1 Aleatorio en [0,1)  (posible pero con sesgo positivo no deseado)
    idx = np.arange(len(y))
    if shuffle:
        rng.shuffle(idx)
    for i in idx:
        w += eta * y[i] * Xb[i]
    return w

def hebb_predict(X, w):
    Xb = augment_bias(X)
    s = Xb @ w
    yhat = np.where(s >= 0, 1.0, -1.0)
    return yhat, s


# Debe existir 'datos.csv' con columnas: x1, x2, x3, clase
df = pd.read_csv("datos_petroleo.csv")
X = df[["x1","x2","x3"]].to_numpy(dtype=float)   # (N,3)
y = to_pm1(df["D"])                           # (N,)
print(X.shape, y.shape, np.unique(y, return_counts=True))


rng = np.random.default_rng(0)
N = len(y)
idx = rng.permutation(N)
p = int(0.8 * N)

itr, ite = idx[:p], idx[p:]
Xtr, Xte = X[itr], X[ite]
ytr, yte = y[itr], y[ite]

print("train:", Xtr.shape, "test:", Xte.shape)


# Ajuste en TRAIN normaniza, estandariza datos 
mu = Xtr.mean(axis=0)
sigma = Xtr.std(axis=0)
sigma[sigma == 0] = 1.0  # evita división por cero

# Transformación
Xtr_std = (Xtr - mu) / sigma
Xte_std = (Xte - mu) / sigma


w = hebb_train(Xtr_std, ytr, eta=1.0, shuffle=True, rng=rng)
yhat_tr, _ = hebb_predict(Xtr_std, w)
yhat_te, _ = hebb_predict(Xte_std, w)
print("Pesos (w0,w1,w2,w3):", w)


def confusion(y_true, y_pred):
    from collections import Counter
    c = Counter(zip(y_true.astype(int), y_pred.astype(int)))
    tp = c[(1,1)]; tn = c[(-1,-1)]
    fp = c[(-1,1)]; fn = c[(1,-1)]
    return dict(c), tp, tn, fp, fn

# Train
yhat_tr, s_tr = hebb_predict(Xtr, w)
acc_tr = (yhat_tr == ytr).mean()
cm_tr, tp, tn, fp, fn = confusion(ytr, yhat_tr)
prec_pos = tp/(tp+fp) if (tp+fp)>0 else 0.0
rec_pos  = tp/(tp+fn) if (tp+fn)>0 else 0.0

# Test
yhat_te, s_te = hebb_predict(Xte, w)
acc_te = (yhat_te == yte).mean()
cm_te, TP, TN, FP, FN = confusion(yte, yhat_te)
prec_pos_te = TP/(TP+FP) if (TP+FP)>0 else 0.0
rec_pos_te  = TP/(TP+FN) if (TP+FN)>0 else 0.0

print(f"Train acc: {acc_tr:.3f} | Prec(+1): {prec_pos:.3f} | Rec(+1): {rec_pos:.3f}")
print("Matriz confusión train {(y,ŷ):conteo}:", cm_tr)
print(f"Test  acc: {acc_te:.3f} | Prec(+1): {prec_pos_te:.3f} | Rec(+1): {rec_pos_te:.3f}")
print("Matriz confusión test  {(y,ŷ):conteo}:", cm_te)


X_new = np.array([

[-0.3565, 0.0620, 5.9891],
[-0.7842, 1.1267, 5.5912],
[0.3012, 0.5611, 5.8234],
[0.7757, 1.0648, 8.0677],
[0.1570, 0.8028, 6.3040],
[-0.7014, 1.0316, 3.6005],
[0.3748, 0.1536, 6.1537],
[-0.6920, 0.9404, 4.4058],
[-1.3970, 0.7141, 4.9263],
[-1.8842, -0.2805, 1.2548]

    
], dtype=float)

y_new, s_new = hebb_predict(X_new, w)

X_new_std = (X_new - mu) / sigma
y_new, s_new = hebb_predict(X_new_std, w)

print("ŷ nuevos:", y_new.astype(int))
print("scores:", s_new)  # distancia firmada al hiperplano






























